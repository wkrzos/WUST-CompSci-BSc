{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cl7f8AwaBSI5"
      },
      "source": [
        "### Regresja przy użyciu biblioteki sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pobierzmy ponownie zbiór znany z poprzednich laboratoriów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plik GDP_happiness.csv już jest na dysku\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GDP per capita</th>\n",
              "      <th>happiness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Belgium</th>\n",
              "      <td>133.000000</td>\n",
              "      <td>6.864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bulgaria</th>\n",
              "      <td>28.200000</td>\n",
              "      <td>5.102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Czech Republic</th>\n",
              "      <td>67.400000</td>\n",
              "      <td>6.911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Denmark</th>\n",
              "      <td>172.500000</td>\n",
              "      <td>7.646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Germany</th>\n",
              "      <td>133.200000</td>\n",
              "      <td>7.076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Estonia</th>\n",
              "      <td>68.100000</td>\n",
              "      <td>6.022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ireland</th>\n",
              "      <td>231.900000</td>\n",
              "      <td>7.094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Greece</th>\n",
              "      <td>54.900000</td>\n",
              "      <td>5.515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Spain</th>\n",
              "      <td>84.800000</td>\n",
              "      <td>6.401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>France</th>\n",
              "      <td>115.400000</td>\n",
              "      <td>6.664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Croatia</th>\n",
              "      <td>42.800000</td>\n",
              "      <td>5.505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Italy</th>\n",
              "      <td>95.200000</td>\n",
              "      <td>6.387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cyprus</th>\n",
              "      <td>81.200000</td>\n",
              "      <td>6.159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lithuania</th>\n",
              "      <td>56.000000</td>\n",
              "      <td>6.215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Luxembourg</th>\n",
              "      <td>327.900000</td>\n",
              "      <td>7.238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hungary</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>6.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Malta</th>\n",
              "      <td>85.600000</td>\n",
              "      <td>6.773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Netherlands</th>\n",
              "      <td>149.900000</td>\n",
              "      <td>7.449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Austria</th>\n",
              "      <td>143.700000</td>\n",
              "      <td>7.294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Poland</th>\n",
              "      <td>44.500000</td>\n",
              "      <td>6.186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Portugal</th>\n",
              "      <td>66.500000</td>\n",
              "      <td>5.911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Romania</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>6.124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Slovenia</th>\n",
              "      <td>74.300000</td>\n",
              "      <td>6.363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Slovakia</th>\n",
              "      <td>55.200000</td>\n",
              "      <td>6.281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Finland</th>\n",
              "      <td>139.800000</td>\n",
              "      <td>7.809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sweden</th>\n",
              "      <td>148.100000</td>\n",
              "      <td>7.353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Great Britain</th>\n",
              "      <td>121.200000</td>\n",
              "      <td>7.165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Iceland</th>\n",
              "      <td>195.700000</td>\n",
              "      <td>7.504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Norway</th>\n",
              "      <td>217.300000</td>\n",
              "      <td>7.488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Switzerland</th>\n",
              "      <td>244.500000</td>\n",
              "      <td>7.560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Montenegro</th>\n",
              "      <td>25.500000</td>\n",
              "      <td>5.546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Albania</th>\n",
              "      <td>15.300000</td>\n",
              "      <td>4.883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Serbia</th>\n",
              "      <td>21.200000</td>\n",
              "      <td>5.778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turkey</th>\n",
              "      <td>26.400000</td>\n",
              "      <td>5.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latvia</th>\n",
              "      <td>104.476471</td>\n",
              "      <td>5.950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                GDP per capita  happiness\n",
              "Belgium             133.000000      6.864\n",
              "Bulgaria             28.200000      5.102\n",
              "Czech Republic       67.400000      6.911\n",
              "Denmark             172.500000      7.646\n",
              "Germany             133.200000      7.076\n",
              "Estonia              68.100000      6.022\n",
              "Ireland             231.900000      7.094\n",
              "Greece               54.900000      5.515\n",
              "Spain                84.800000      6.401\n",
              "France              115.400000      6.664\n",
              "Croatia              42.800000      5.505\n",
              "Italy                95.200000      6.387\n",
              "Cyprus               81.200000      6.159\n",
              "Lithuania            56.000000      6.215\n",
              "Luxembourg          327.900000      7.238\n",
              "Hungary              48.000000      6.000\n",
              "Malta                85.600000      6.773\n",
              "Netherlands         149.900000      7.449\n",
              "Austria             143.700000      7.294\n",
              "Poland               44.500000      6.186\n",
              "Portugal             66.500000      5.911\n",
              "Romania              37.000000      6.124\n",
              "Slovenia             74.300000      6.363\n",
              "Slovakia             55.200000      6.281\n",
              "Finland             139.800000      7.809\n",
              "Sweden              148.100000      7.353\n",
              "Great Britain       121.200000      7.165\n",
              "Iceland             195.700000      7.504\n",
              "Norway              217.300000      7.488\n",
              "Switzerland         244.500000      7.560\n",
              "Montenegro           25.500000      5.546\n",
              "Albania              15.300000      4.883\n",
              "Serbia               21.200000      5.778\n",
              "Turkey               26.400000      5.132\n",
              "Latvia              104.476471      5.950"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "plik = 'GDP_happiness.csv'\n",
        "URL = \"https://byes.pl/wp-content/uploads/datasets/\" + plik\n",
        "if not os.path.isfile(plik):\n",
        "    print('Pobieram plik z ', URL)\n",
        "    urllib.request.urlretrieve(URL, plik)\n",
        "    print('Pobrano plik')\n",
        "else:\n",
        "    print(f'Plik {plik} już jest na dysku')\n",
        "\n",
        "dane = pd.read_csv(plik, index_col=[0])\n",
        "dane = dane.fillna(dane.mean(axis=0))\n",
        "dane.tail()\n",
        "\n",
        "display(dane)\n",
        "\n",
        "X = dane['GDP per capita'].values\n",
        "Y = dane['happiness'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVRGejydlYbm"
      },
      "source": [
        "### Metody z biblioteki [Scikit-learn](https://scikit-learn.org/stable/)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq39cjsZtKgy"
      },
      "source": [
        "Metody uczenia maszynowego, czy to do klasyfikacji, regresji, grupowania, czy dopasowywania rozkładów do danych, dostępne w bibliotece Scikit-learn nazywane są - nie wiedzieć czemu - *estymatorami*. <br>\n",
        "Sposób korzystania z każdego estymatora został ujednolicony. Oto przykład regresji liniowej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "unrPWt1sll55"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_doi8LQgvP6p"
      },
      "source": [
        "2. Utworzenie instancji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2osyzJ77vkfy"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'LinearRegression' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_lin \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
          ]
        }
      ],
      "source": [
        "model_lin = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvviY4h0v0Tn"
      },
      "source": [
        "3. Dopasowanie *estymatora* do danych metodą ```fit```: patrz komentarz pod algorytmem (4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwnQXeeNwIib",
        "outputId": "a74807c2-7419-47e0-d801-72ddcd95d384"
      },
      "outputs": [],
      "source": [
        "model_lin.fit(X.reshape(-1,1), Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p65CUcgmygea"
      },
      "source": [
        "4. Obliczenia/predykcje z wykorzystaniem metody ```predict``` *estymatora*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "N5zkWAU7xCxr",
        "outputId": "d0e06064-25c9-4a39-bc6a-11533b009897"
      },
      "outputs": [],
      "source": [
        "X_test = np.linspace(start=X.min(), stop=X.max(), num=300)\n",
        "Y_pred = model_lin.predict(X_test.reshape(-1,1))\n",
        "\n",
        "plt.scatter(X,Y, alpha=0.7)\n",
        "plt.plot(X_test, Y_pred, color='tab:orange', linewidth=3)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mmeipMdSDnEh"
      },
      "source": [
        "Można też sprawdzić wartości parametrów otrzymanego modelu liniowego."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXloVGWlD1a_",
        "outputId": "e515abad-7d2d-41cd-fd4d-2753f0bef54c"
      },
      "outputs": [],
      "source": [
        "print(f'Parametry modelu liniowego: a = {np.round(model_lin.coef_,5)}, b = {np.round(model_lin.intercept_,5)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1R1BQDF0Xbf"
      },
      "source": [
        "Oto inne ważne czynności, które wykonuje się w ramach dopasowywania modelu do danych."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBRTer200rhs"
      },
      "source": [
        "Podział zbioru na część do trenowania i testowania"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgeDrvSDy45s"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XDPNP_lX05NR"
      },
      "source": [
        "Wskaźnik jakości modelu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_btep5W02XV",
        "outputId": "16b4828b-99f6-4d41-8e25-6543b8c57f05"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(Y, model_lin.predict(X.reshape(-1,1)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ćwiczenie 1:** Korzystając z dokumentacji sklearn oblicz dla powyższych danych pierwiastek błędu średniokwadratowego (ang. root mean square error)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M3TtxyfS2Enx"
      },
      "source": [
        "Oto **przykład** demonstrujący jednolitość obsługi *estymatorów* biblioteki Scikit-learn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "0K_CNSM31Cag",
        "outputId": "4f9b3cf8-cc46-4179-953e-502fbd86940e"
      },
      "outputs": [],
      "source": [
        "X = dane['GDP per capita'].values\n",
        "Y = dane['happiness'].values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
        "\n",
        "\n",
        "# =========  Model liniowy =========\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model_lin = LinearRegression()\n",
        "model_lin.fit(X_train.reshape(-1,1), Y_train)\n",
        "\n",
        "print(f'Parametry modelu liniowego: {np.round(model_lin.coef_,5)}, {np.round(model_lin.intercept_,5)}')\n",
        "MSE_lin = mean_squared_error(Y_test, model_lin.predict(X_test.reshape(-1,1)))\n",
        "print(f'Błąd średniokwadratowy modelu liniowego: {MSE_lin:0.3}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== Uogólniony model liniowy (ang. Generalized Linear Model) =====\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "model_GLM = LinearRegression()\n",
        "gen_features = PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)\n",
        "model_GLM.fit(gen_features.fit_transform(X_train.reshape(-1,1)), Y_train)\n",
        "\n",
        "print(f'Parametry modelu GLM: {np.round(model_GLM.coef_,4)}, {np.round(model_GLM.intercept_,5)}')\n",
        "MSE_GLM = mean_squared_error(Y_test, model_GLM.predict(gen_features.fit_transform(X_test.reshape(-1,1))))\n",
        "print(f'Błąd średniokwadratowy modelu GLM: {MSE_GLM:0.3}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#==== Maszyna wektorów wspierających (ang. Support Vector Machine) ====\n",
        "# SVR dla regresji, SVC dla klasyfikacji\n",
        "from sklearn.svm import SVR\n",
        "model_svr = SVR(kernel='rbf', gamma='scale', C=1)\n",
        "\n",
        "model_svr.fit(X_train.reshape(-1,1), Y_train)\n",
        "MSE_SVR = mean_squared_error(Y_test, model_svr.predict(X_test.reshape(-1,1)))\n",
        "print(f'Błąd średniokwadratowy modelu SVR: {MSE_SVR:0.3}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predykcje wszystkich modeli dla całego zakresów osi X\n",
        "os_x = np.linspace(start=X.min(), stop=X.max(), num=300)\n",
        "y_lin_pred = model_lin.predict(os_x.reshape(-1,1))\n",
        "y_GLM_pred = model_GLM.predict(gen_features.fit_transform(os_x.reshape(-1,1)))\n",
        "y_svr_pred = model_svr.predict(os_x.reshape(-1,1))\n",
        "\n",
        "# Wizualizacja\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(X_train, Y_train, label='dane treningowe', alpha=0.7)\n",
        "plt.scatter(X_test, Y_test, edgecolor='black', facecolor='none', label='dane testujące')\n",
        "plt.plot(os_x, y_lin_pred, label='model liniowy', color='tab:orange')\n",
        "plt.plot(os_x, y_GLM_pred, label=f'model GLM', color='tab:red')\n",
        "plt.plot(os_x, y_svr_pred, label='model SVR', color='tab:green')\n",
        "plt.xlabel(dane.columns[0], fontsize=14)\n",
        "plt.ylabel(dane.columns[1], fontsize=14)\n",
        "plt.legend(fontsize=12, shadow=True, loc='lower right')\n",
        "plt.ylim([Y.min()-0.1, Y.max()+0.5])\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "foKbvjFLghLc"
      },
      "source": [
        "**Ćwiczenie 2:** Wykonaj wielokrotne dopasowania modeli do różnych podziałów zbioru danych na część do trenowania i do testowania. Wyciągnij wnioski. <br>\n",
        "Jak oceniasz adekwatność każdego z modeli, tzn. czy poprawnie opisuje tendencje obserwowane w danych? <br>\n",
        "Jaki kolejny model proponujesz rozważyć? <br>\n",
        "Jak można ocenić adekwatność modelu w przypadku danych wielowymiarowych?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wykorzystanie SVM do zadania klasyfikacji na podstawie zbioru Iris\n",
        "W celu przetestowania maszyny wektorów nośnych na problemie klasyfikacji, pobierzmy zbiór Iris.\n",
        "\n",
        "Zbiór danych Iris zawiera pomiary cech trzech różnych gatunków roślin z rodzaju kosaciec (ang. iris). Zbiór ten zawiera cztery cechy dla każdego z 150 obserwowanych kwiatów - długość i szerokość działek kielicha oraz płatków oraz długość i szerokość słupka.\n",
        "\n",
        "Wszystkie wartości pomiarów zostały znormalizowane do jednostek centymetrów. Zbiór ten jest często wykorzystywany w zadaniach klasyfikacji i uczenia maszynowego jako przykład problemu wieloklasowej klasyfikacji.\n",
        "\n",
        "<!-- . It contains measurements of physical features of three species of iris flowers: Iris setosa, Iris versicolor, and Iris virginica. The measurements include the length and width of the petals and sepals of each flower, which were collected by the statistician Ronald Fisher in 1936. The dataset has become a classic example of data analysis and machine learning due to its simplicity and versatility, and is commonly used for classification tasks, data visualization, and exploratory data analysis. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Badania eksploracyjne mające na celu poznanie istoty problemu oraz zbadanie danych na jakich się opieramy to pierwszy krok do rozwiązania problemu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = iris.data  # dane wejściowe\n",
        "y = iris.target  # dane wyjściowe"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ćwiczenie 3:** Wykonaj badania eksploracyjne (ang. exploratory data analysis) i odpowiedz na następujące pytania:\n",
        "1) z jakich danych składają się dane wejściowe i dane wyjściowe?\n",
        "2) jaka jest sumaryczna liczba próbek?\n",
        "3) jaka jest liczba różnych klas kwiatów?\n",
        "4) ile próbek zawiera każda z klas? Czy klasy są zbalansowane?\n",
        "5) jakie są średnia i odchylenie standardowe cechy `petal width (cm)`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ćwiczenie 4:** Wykorzystaj metodę `train_test_split` i podziel zbiór danych na podzbiory treningowy oraz testowy w stosunku 75:25 z wykorzystaniem ziarna losowości o wartości 13 oraz wykorzystując przetasowanie (ang. shuffle) danych.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "W sklearn modele klasyfikacji tworzymy w analogiczny sposób jak modele regresji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC(kernel='rbf')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dobrą praktyką, zanim przekażemy dane do klasyfikatora, jest przeskalowanie ich.\n",
        "\n",
        "Ma to na celu zapewnienie równego znaczenia każdej z cech. Z racji, iż SVM próbuje znaleźć optymalną granicę decyzyjną, która separuje klasy w przestrzeni cech, to jeśli cechy wejściowe używają różnych skali, to niektóre z nich mogą mieć większy zakres wartości niż inne. To może powodować, że SVM położy większy nacisk na cechy o większych skalach, a więc nierównomiernie uwzględnieni (bardziej skupi się) poszczególne z nich w procesie uczenia.\n",
        "\n",
        "\n",
        "\n",
        "W tym celu wykorzystajmy API sklearn, a dokładniej klasę `StandardScaler`. Podobnie jak w przypadku modeli - tutaj również wywołujemy funkcję `fit()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "sc.fit(X_train)\n",
        "\n",
        "X_train_sc = sc.transform(X_train)\n",
        "X_test_sc = sc.transform(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ćwiczenie 5:** jak zmieniły się wartości poszczególnych cech po skalowaniu? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podobnie jak w przypadku modeli regresji funkcja `fit()` jest używana do trenowania modelu na danych treningowych problemu klasyfikacji.\n",
        "\n",
        "Funkcja `predict()` zwraca przewidywane etykiety dla danych testowych, które wcześniej nie były używane do dopasowania modelu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ocena jakości modelu klasyfikacji\n",
        "\n",
        "Na poprzednich laboratoriach poznaliśmy sposoby oceny jakości predykcji modelu regresji. W zagadnieniu klasyfikacji również istnieje szereg metod pozwalających na takową ocenę - stosować je będziemy w zależnosci od problemu.\n",
        "\n",
        "Tablica pomyłek (ang. confusion matrix) to macierz $N\\times N$, gdzie $N$ to liczba klas docelowych. Jest ona używana do oceny wyników modeli klasyfikacyjnych. Jedna z osi przedstawia prawdziwe klasy, podczas gdy druga - predykowane przez nasz model. Wartości w odpowiednich komórkach mówią o tym ile próbek zostało zaklasyfikowanych w dany sposób.\n",
        "\n",
        "Intuicyjnie dążymy do tego, by otrzymać jak najwiecęj wartości po przekątnej - tzn. by jak najwięcej klas było predykowanych jako te właściwe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[clf.classes_])\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm,\n",
        "   display_labels=[\"Iris setosa\", \"Iris virginica\", \"Iris versicolor\"],\n",
        ")\n",
        "disp.plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ćwiczenie 6:** Opisz jakie błędy popełnił klasyfikator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bazując na tablicy pomyłek jesteśmy w stanie policzyć różne metryki klasyfikacji. Najbardziej podstawową z nich jest dokładność (ang. accuracy).\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Dokładność} = \\frac{\\text{liczba poprawnie zaklasyfikowanych próbek}}{\\text{liczba wszystkich próbek}}\n",
        "\\end{equation}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ćwiczenie 7**: wykorzystując bibliotekę sklearn (moduł `sklearn.metrics`) oblicz wartość dokładności dla predykcji zbioru testowego Iris. Czy wyniki osiągnięte przez klasyfikator można uznać za dobre?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podstawą poprawnego wykonania zadania jest dobranie odpowiednich narzędzi - dokładność nie zawsze jest najlepszą metryką. Chcąc przedstawić bardziej miarodajne wnioski warto jest używać metryk takich jak precyzja (ang. precision), czułość (ang. recall) lub F1-score - przeczytaj o nich więcej w domu."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wizualizacja parametrów SVM"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Poniższy kod wizualizuje granice decyzyjne dla różnych przykładów SVMów. Poeksperymentuj poprzez podanie różnych wartości parametrów.\n",
        "\n",
        "\n",
        "Oryginalna implementacja poniższego kodu znajduje się [tutaj](https://scikit-learn.org/stable/auto_examples/exercises/plot_iris_exercise.html#sphx-glr-auto-examples-exercises-plot-iris-exercise-py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Chcemy analizować klasyfikację tylko pomiędzy dwiema klasami\n",
        "X = X[y != 0, :2]\n",
        "y = y[y != 0]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=42, shuffle=True)\n",
        "\n",
        "y_train = y_train.astype(float)\n",
        "y_test = y_test.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Podstawowe parametry do modyfikacji, więcej parametrów znajdziesz na https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "C = 1.0\n",
        "gamma = 10.0\n",
        "\n",
        "# Wygeneruj wizualizację dla każdego z modeli\n",
        "for kernel in (\"linear\", \"rbf\", \"poly\"):\n",
        "    clf = svm.SVC(kernel=kernel, gamma=gamma, C=C)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.clf()\n",
        "\n",
        "    # Zwizualizuj wszystkie próbki\n",
        "    plt.scatter(\n",
        "        X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.Paired, edgecolor=\"k\", s=20\n",
        "    )\n",
        "\n",
        "    # Zaznacz okręgiem dane testowe\n",
        "    plt.scatter(\n",
        "        X_test[:, 0], X_test[:, 1], s=80, facecolors=\"none\", zorder=10, edgecolor=\"k\"\n",
        "    )\n",
        "\n",
        "    plt.axis(\"tight\")\n",
        "    x_min = X[:, 0].min()\n",
        "    x_max = X[:, 0].max()\n",
        "    y_min = X[:, 1].min()\n",
        "    y_max = X[:, 1].max()\n",
        "\n",
        "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
        "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
        "\n",
        "    # Wykreśl granicę decyzyjną\n",
        "    Z = Z.reshape(XX.shape)\n",
        "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
        "    plt.contour(\n",
        "        XX,\n",
        "        YY,\n",
        "        Z,\n",
        "        colors=[\"k\", \"k\", \"k\"],\n",
        "        linestyles=[\"--\", \"-\", \"--\"],\n",
        "        levels=[-0.5, 0, 0.5],\n",
        "    )\n",
        "\n",
        "    plt.title(kernel)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ćwiczenie 8**: Poznaliśmy do tej pory różne parametry maszyny wektorów nośnych (C, gamma) oraz operacje które warto wykonać przed przekazaniem danych do modelu (skalowanie danych). Sprawdź wpływ ww. czynników na wyniki SVM na zbiorze Iris. Pamiętaj o zachowaniu miarodajności wyników poprzez użycie tych samych zbiorów oraz losowości!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MSiD_3_metoda najmniejszych kwadratów.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
